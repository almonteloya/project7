{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff266bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Union\n",
    "from numpy.typing import ArrayLike\n",
    "from nn.nn import NeuralNetwork_Lau\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nn.nn2 import NeuralNetwork\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85562a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_ar = [{'input_dim': 64, 'output_dim': 16, 'activation' : 'Relu'}, {'input_dim': 16, 'output_dim': 64, 'activation': 'Relu'}]\n",
    "nn_ar2 = [{'input_dim': 64, 'output_dim': 16, 'activation' : 'relu'}, {'input_dim': 16, 'output_dim': 64, 'activation': 'relu'}]\n",
    "\n",
    "lr = .0001\n",
    "seed = 10\n",
    "batch_size = 1\n",
    "epochs = 2\n",
    "loss_function = \"mse\"\n",
    "\n",
    "testlau = NeuralNetwork_Lau(nn_ar,lr, seed, batch_size,epochs,loss_function)\n",
    "testj = NeuralNetwork(nn_ar2,lr, seed, batch_size,epochs,loss_function)\n",
    "\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, X, test_size=0.33, random_state=42)\n",
    "num_batches = int(X_train.shape[0]/(batch_size)) + 1\n",
    "X_batch = np.array_split(X_train, num_batches)\n",
    "y_batch = np.array_split(y_train, num_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e1efd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lau, cache_lau = testlau.forward(X_batch[1])\n",
    "y_pred_j, cache_j = testj.forward(X_batch[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830dbdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_lau = testlau._loss_function(y_batch[1],y_pred_lau)\n",
    "loss_train_j = testj._mean_squared_error(y_batch[1], y_pred_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8309532",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_dict = testj.backprop(y_batch[1], y_pred_j, cache_j)\n",
    "grad_dict = testlau.backprop(y_batch[1],  y_pred_j, cache_j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b480ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dy_hatj = testj._mean_squared_error_backprop(y_batch[1], y_pred_j)\n",
    "dL_dy_hatl = testlau._mean_squared_error_backprop(y_batch[1], y_pred_j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e7d269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.        ,   2.67386902,   4.78010643, -30.        ,\n",
       "        -29.89303701,  -1.74536342,   0.65050905,  -0.        ,\n",
       "         -0.        ,   5.39618172,  -0.        , -22.40247207,\n",
       "        -29.91181401, -13.27634525,  -0.        ,  -0.        ,\n",
       "         -0.        ,  -0.        ,  -0.        , -28.        ,\n",
       "        -32.        , -10.        ,   1.58845129,   0.30871116,\n",
       "          4.02750222,   2.48242099,  -0.        , -26.        ,\n",
       "        -32.        ,  -3.12553268,   2.96554716,  -0.        ,\n",
       "          3.00715201,   6.45513246,  -4.        , -32.        ,\n",
       "        -23.36499743,  -0.        ,  -0.        ,  -0.        ,\n",
       "         -0.        ,   3.08361186, -12.        , -28.8866463 ,\n",
       "        -26.        ,  -0.        ,   0.04031812,  -0.        ,\n",
       "         -0.        ,   2.09752445, -12.        , -31.47712619,\n",
       "        -22.        ,   0.60663436,   0.49966216,   5.54278285,\n",
       "         -0.        ,  -0.        ,  -2.        , -28.        ,\n",
       "        -31.87828219, -10.20295968,   5.66948769,   0.41743948]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL_dy_hatj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94791e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reversed(range(len(self.arch))):\n",
    "    index_L = i + 1\n",
    "## Do a single back drop\n",
    "    dA_prev, dW_curr, db_curr = self._single_backprop(\n",
    "        W_curr = self._param_dict['W'+ str(index_L)],\n",
    "        b_curr = self._param_dict['b'+ str(index_L)],\n",
    "        Z_curr = cache['Z'+ str(index_L)],\n",
    "        A_prev = cache['A'+ str(index_L - 1)], ## remember is the previous \n",
    "        dA_curr = dA_curr,\n",
    "        activation_curr = self.arch[index_L-1][\"activation\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69e00312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00901729 -0.00374486 -0.2333174  ...  0.11961801 -0.18391746\n",
      "   0.11093813]\n",
      " [ 0.05481775 -0.11517205  0.04097154 ... -0.0554164   0.04817048\n",
      "   0.16345027]\n",
      " [ 0.07020614 -0.06432666  0.12411124 ...  0.02904223  0.01219425\n",
      "   0.23175571]\n",
      " ...\n",
      " [-0.019025    0.04249361 -0.01719086 ...  0.03303231  0.09613501\n",
      "   0.02452599]\n",
      " [ 0.13349883  0.02282172 -0.01149832 ... -0.13390422 -0.217995\n",
      "   0.20851854]\n",
      " [ 0.00420896 -0.02710579 -0.01703923 ... -0.0493259   0.07909607\n",
      "   0.00949581]] [[ 0.05279101]\n",
      " [-0.0392527 ]\n",
      " [ 0.07960745]\n",
      " [-0.06932727]\n",
      " [ 0.10523608]\n",
      " [-0.00461298]\n",
      " [-0.08342739]\n",
      " [ 0.0550901 ]\n",
      " [ 0.02052925]\n",
      " [-0.06612227]\n",
      " [-0.20896491]\n",
      " [ 0.05928049]\n",
      " [ 0.06646292]\n",
      " [ 0.01502987]\n",
      " [-0.12389492]\n",
      " [-0.0534371 ]\n",
      " [ 0.06978137]\n",
      " [-0.0942077 ]\n",
      " [-0.08503389]\n",
      " [-0.06744982]\n",
      " [ 0.10956076]\n",
      " [-0.08465231]\n",
      " [-0.14229286]\n",
      " [ 0.01539745]\n",
      " [ 0.11848053]\n",
      " [-0.12533676]\n",
      " [ 0.05492611]\n",
      " [ 0.06947691]\n",
      " [-0.06002501]\n",
      " [-0.01393253]\n",
      " [ 0.00321322]\n",
      " [-0.00701551]\n",
      " [-0.09678883]\n",
      " [ 0.13506682]\n",
      " [-0.17708794]\n",
      " [-0.06975971]\n",
      " [-0.02905593]\n",
      " [ 0.13221669]\n",
      " [-0.1017258 ]\n",
      " [ 0.11029765]\n",
      " [-0.04649303]\n",
      " [-0.08331541]\n",
      " [-0.15365066]\n",
      " [ 0.09650997]\n",
      " [-0.12021778]\n",
      " [-0.00047842]\n",
      " [-0.00784945]\n",
      " [ 0.06291137]\n",
      " [-0.09203999]\n",
      " [ 0.07152466]\n",
      " [ 0.01585432]\n",
      " [ 0.0314936 ]\n",
      " [-0.12216017]\n",
      " [ 0.12131427]\n",
      " [ 0.03793427]\n",
      " [ 0.01999964]\n",
      " [ 0.05389434]\n",
      " [-0.23684163]\n",
      " [ 0.04494447]\n",
      " [ 0.23468523]\n",
      " [-0.14390758]\n",
      " [ 0.05122949]\n",
      " [ 0.16459207]\n",
      " [-0.00227985]] [[-1.24874243  1.33693451  3.39005322 -0.53929491  0.05348149  1.12731829\n",
      "   0.32525453 -1.27237176 -2.85886561  2.69809086 -0.97645159  0.79876397\n",
      "   1.044093    0.36182737 -1.42514595 -3.05037259 -0.48205311 -0.63948519\n",
      "  -1.6198192  -1.04666887 -1.53497194 -0.57282802  0.79422565  0.15435558\n",
      "   2.01375111  1.24121049 -0.73628695 -1.26393742 -0.57643092  0.43723366\n",
      "   1.48277358 -1.34542764  1.503576    3.22756623 -0.29891638 -0.74139754\n",
      "   1.31750129 -1.09971633 -2.5399361  -0.05272403 -3.59865728  1.54180593\n",
      "  -0.19711011  1.55667685 -0.72227665 -0.40462473  0.02015906 -0.57351786\n",
      "  -2.39490585  1.04876223 -2.37816596  0.26143691 -1.87766586  0.30331718\n",
      "   0.24983108  2.77139143 -0.35659678 -0.2560969  -0.53620973 -0.20815723\n",
      "   0.0608589   1.89852016  2.83474385  0.20871974]] [[ 0.          1.1035368   0.          0.         13.46451706  0.78962229\n",
      "   0.          0.          0.          3.1689744   2.27292549  0.\n",
      "   0.          0.          0.          5.21107591]] [[ -0.           2.67386902   4.78010643 -30.         -29.89303701\n",
      "   -1.74536342   0.65050905  -0.          -0.           5.39618172\n",
      "   -0.         -22.40247207 -29.91181401 -13.27634525  -0.\n",
      "   -0.          -0.          -0.          -0.         -28.\n",
      "  -32.         -10.           1.58845129   0.30871116   4.02750222\n",
      "    2.48242099  -0.         -26.         -32.          -3.12553268\n",
      "    2.96554716  -0.           3.00715201   6.45513246  -4.\n",
      "  -32.         -23.36499743  -0.          -0.          -0.\n",
      "   -0.           3.08361186 -12.         -28.8866463  -26.\n",
      "   -0.           0.04031812  -0.          -0.           2.09752445\n",
      "  -12.         -31.47712619 -22.           0.60663436   0.49966216\n",
      "    5.54278285  -0.          -0.          -2.         -28.\n",
      "  -31.87828219 -10.20295968   5.66948769   0.41743948]] Relu\n",
      "[[ 0.13315865  0.0715279  -0.15454003 ... -0.05017289  0.11287852\n",
      "  -0.069781  ]\n",
      " [-0.00811222 -0.05292961  0.10461829 ...  0.03462331  0.10225161\n",
      "   0.01668103]\n",
      " [ 0.16567166  0.06678896 -0.02299466 ...  0.07817752  0.03534776\n",
      "  -0.02072795]\n",
      " ...\n",
      " [-0.15177962 -0.19219949 -0.03433452 ...  0.04771456  0.05710074\n",
      "   0.02540695]\n",
      " [-0.02412388 -0.19168866  0.01011951 ...  0.09462987  0.02242274\n",
      "   0.08335147]\n",
      " [-0.09689893  0.08641705 -0.10443831 ...  0.02114479 -0.13327253\n",
      "  -0.02075699]] [[-0.00078292]\n",
      " [ 0.03652662]\n",
      " [-0.0400028 ]\n",
      " [ 0.11325255]\n",
      " [-0.00986163]\n",
      " [-0.02110222]\n",
      " [-0.15802377]\n",
      " [-0.09296642]\n",
      " [-0.05979036]\n",
      " [-0.14329707]\n",
      " [-0.04669586]\n",
      " [-0.08941448]\n",
      " [-0.33176691]\n",
      " [ 0.08952796]\n",
      " [ 0.11996294]\n",
      " [ 0.03816046]] [[-5.4887395   1.1035368  -4.92618313 -2.44393267 13.46451706  0.78962229\n",
      "  -4.01696177 -5.49825301 -8.83516295  3.1689744   2.27292549 -2.55621861\n",
      "  -9.99391166 -6.43197682 -8.91550968  5.21107591]] [[ 0.  0.  1. 15. 15.  2.  0.  0.  0.  0.  0. 12. 16.  7.  0.  0.  0.  0.\n",
      "   0. 14. 16.  5.  0.  0.  0.  0.  0. 13. 16.  2.  0.  0.  0.  0.  2. 16.\n",
      "  13.  0.  0.  0.  0.  0.  6. 16. 13.  0.  0.  0.  0.  0.  6. 16. 11.  0.\n",
      "   0.  0.  0.  0.  1. 14. 16.  7.  0.  0.]] [[ -0.           2.67386902   4.78010643 -30.         -29.89303701\n",
      "   -1.74536342   0.65050905  -0.          -0.           5.39618172\n",
      "   -0.         -22.40247207 -29.91181401 -13.27634525  -0.\n",
      "   -0.          -0.          -0.          -0.         -28.\n",
      "  -32.         -10.           1.58845129   0.30871116   4.02750222\n",
      "    2.48242099  -0.         -26.         -32.          -3.12553268\n",
      "    2.96554716  -0.           3.00715201   6.45513246  -4.\n",
      "  -32.         -23.36499743  -0.          -0.          -0.\n",
      "   -0.           3.08361186 -12.         -28.8866463  -26.\n",
      "   -0.           0.04031812  -0.          -0.           2.09752445\n",
      "  -12.         -31.47712619 -22.           0.60663436   0.49966216\n",
      "    5.54278285  -0.          -0.          -2.         -28.\n",
      "  -31.87828219 -10.20295968   5.66948769   0.41743948]] Relu\n"
     ]
    }
   ],
   "source": [
    "for i in reversed(range(len(testlau.arch))):\n",
    "    index_L = i + 1\n",
    "## Do a single back drop\n",
    "    print (index_L)\n",
    "    W_curr = testlau._param_dict['W'+ str(index_L)]\n",
    "    b_curr = testlau._param_dict['b'+ str(index_L)]\n",
    "    Z_curr = cache_lau['Z'+ str(index_L)]\n",
    "    A_prev = cache_lau['A'+ str(index_L - 1)] ## remember is the previous \n",
    "    dA_curr = dA_curr\n",
    "    activation_curr = testlau.arch[index_L-1][\"activation\"]\n",
    "    print(W_curr,b_curr,Z_curr,A_prev,dA_curr,activation_curr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b6a7bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[ 0.00901729 -0.00374486 -0.2333174  ...  0.11961801 -0.18391746\n",
      "   0.11093813]\n",
      " [ 0.05481775 -0.11517205  0.04097154 ... -0.0554164   0.04817048\n",
      "   0.16345027]\n",
      " [ 0.07020614 -0.06432666  0.12411124 ...  0.02904223  0.01219425\n",
      "   0.23175571]\n",
      " ...\n",
      " [-0.019025    0.04249361 -0.01719086 ...  0.03303231  0.09613501\n",
      "   0.02452599]\n",
      " [ 0.13349883  0.02282172 -0.01149832 ... -0.13390422 -0.217995\n",
      "   0.20851854]\n",
      " [ 0.00420896 -0.02710579 -0.01703923 ... -0.0493259   0.07909607\n",
      "   0.00949581]] [[ 0.05279101]\n",
      " [-0.0392527 ]\n",
      " [ 0.07960745]\n",
      " [-0.06932727]\n",
      " [ 0.10523608]\n",
      " [-0.00461298]\n",
      " [-0.08342739]\n",
      " [ 0.0550901 ]\n",
      " [ 0.02052925]\n",
      " [-0.06612227]\n",
      " [-0.20896491]\n",
      " [ 0.05928049]\n",
      " [ 0.06646292]\n",
      " [ 0.01502987]\n",
      " [-0.12389492]\n",
      " [-0.0534371 ]\n",
      " [ 0.06978137]\n",
      " [-0.0942077 ]\n",
      " [-0.08503389]\n",
      " [-0.06744982]\n",
      " [ 0.10956076]\n",
      " [-0.08465231]\n",
      " [-0.14229286]\n",
      " [ 0.01539745]\n",
      " [ 0.11848053]\n",
      " [-0.12533676]\n",
      " [ 0.05492611]\n",
      " [ 0.06947691]\n",
      " [-0.06002501]\n",
      " [-0.01393253]\n",
      " [ 0.00321322]\n",
      " [-0.00701551]\n",
      " [-0.09678883]\n",
      " [ 0.13506682]\n",
      " [-0.17708794]\n",
      " [-0.06975971]\n",
      " [-0.02905593]\n",
      " [ 0.13221669]\n",
      " [-0.1017258 ]\n",
      " [ 0.11029765]\n",
      " [-0.04649303]\n",
      " [-0.08331541]\n",
      " [-0.15365066]\n",
      " [ 0.09650997]\n",
      " [-0.12021778]\n",
      " [-0.00047842]\n",
      " [-0.00784945]\n",
      " [ 0.06291137]\n",
      " [-0.09203999]\n",
      " [ 0.07152466]\n",
      " [ 0.01585432]\n",
      " [ 0.0314936 ]\n",
      " [-0.12216017]\n",
      " [ 0.12131427]\n",
      " [ 0.03793427]\n",
      " [ 0.01999964]\n",
      " [ 0.05389434]\n",
      " [-0.23684163]\n",
      " [ 0.04494447]\n",
      " [ 0.23468523]\n",
      " [-0.14390758]\n",
      " [ 0.05122949]\n",
      " [ 0.16459207]\n",
      " [-0.00227985]] [[0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      "  1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.\n",
      "  0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.]] [[ 0.          1.1035368   0.          0.         13.46451706  0.78962229\n",
      "   0.          0.          0.          3.1689744   2.27292549  0.\n",
      "   0.          0.          0.          5.21107591]] relu\n",
      "0\n",
      "[[ 0.13315865  0.0715279  -0.15454003 ... -0.05017289  0.11287852\n",
      "  -0.069781  ]\n",
      " [-0.00811222 -0.05292961  0.10461829 ...  0.03462331  0.10225161\n",
      "   0.01668103]\n",
      " [ 0.16567166  0.06678896 -0.02299466 ...  0.07817752  0.03534776\n",
      "  -0.02072795]\n",
      " ...\n",
      " [-0.15177962 -0.19219949 -0.03433452 ...  0.04771456  0.05710074\n",
      "   0.02540695]\n",
      " [-0.02412388 -0.19168866  0.01011951 ...  0.09462987  0.02242274\n",
      "   0.08335147]\n",
      " [-0.09689893  0.08641705 -0.10443831 ...  0.02114479 -0.13327253\n",
      "  -0.02075699]] [[-0.00078292]\n",
      " [ 0.03652662]\n",
      " [-0.0400028 ]\n",
      " [ 0.11325255]\n",
      " [-0.00986163]\n",
      " [-0.02110222]\n",
      " [-0.15802377]\n",
      " [-0.09296642]\n",
      " [-0.05979036]\n",
      " [-0.14329707]\n",
      " [-0.04669586]\n",
      " [-0.08941448]\n",
      " [-0.33176691]\n",
      " [ 0.08952796]\n",
      " [ 0.11996294]\n",
      " [ 0.03816046]] [[0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]] [[ 0.  0.  1. 15. 15.  2.  0.  0.  0.  0.  0. 12. 16.  7.  0.  0.  0.  0.\n",
      "   0. 14. 16.  5.  0.  0.  0.  0.  0. 13. 16.  2.  0.  0.  0.  0.  2. 16.\n",
      "  13.  0.  0.  0.  0.  0.  6. 16. 13.  0.  0.  0.  0.  0.  6. 16. 11.  0.\n",
      "   0.  0.  0.  0.  1. 14. 16.  7.  0.  0.]] relu\n"
     ]
    }
   ],
   "source": [
    "for idx, layer in reversed(list(enumerate(testj.arch))):\n",
    "    layer_idx = idx + 1\n",
    "    print (idx)\n",
    "    W_curr = testj._param_dict['W' + str(layer_idx)]\n",
    "    b_curr = testj._param_dict['b' + str(layer_idx)]\n",
    "    Z_curr = cache_j['Z' + str(layer_idx)]\n",
    "    A_prev = cache_j['A' + str(layer_idx-1)]\n",
    "    activation_curr = layer[\"activation\"]\n",
    "    print(W_curr,b_curr,Z_curr,A_prev,activation_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bca927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
